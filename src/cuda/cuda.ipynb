{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup CUDA"
      ],
      "metadata": {
        "id": "BDa_yA0plovE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c13031Ek7eV",
        "outputId": "022b289d-d85d-45ca-8340-03c493567802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNNVgdlqlK3q",
        "outputId": "1ff5a861-3ddf-4d4d-8d3b-99a84a4982ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-028bleof\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-028bleof\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRVuVucVlTEI",
        "outputId": "0bf8cff8-ee99-47d9-92ed-a2414cec5f43"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CUDA Parallelism Code"
      ],
      "metadata": {
        "id": "avXi18_al2jJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kode Percobaan Buat Test Setup Cuda (Bukan Buat Tucil CUDA)"
      ],
      "metadata": {
        "id": "Qdi2cj-uo3DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "    int main() {\n",
        "      std::cout << \"Welcome To GeeksforGeeks\\n\";\n",
        "      return 0;\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YOkiavPlWgC",
        "outputId": "fc764ed1-5b88-4de1-85f7-baaaa5beace9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome To GeeksforGeeks\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "\n",
        "\tusing namespace std;\n",
        "\n",
        "__global__ void maxi(int* a, int* b, int n)\n",
        "{\n",
        "\tint block = 256 * blockIdx.x;\n",
        "\tint max = 0;\n",
        "\n",
        "\tfor (int i = block; i < min(256 + block, n); i++) {\n",
        "\n",
        "\t\tif (max < a[i]) {\n",
        "\t\t\tmax = a[i];\n",
        "\t\t}\n",
        "\t}\n",
        "\tb[blockIdx.x] = max;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "\tint n;\n",
        "\tn = 3 >> 2;\n",
        "\tint a[n];\n",
        "\n",
        "\tfor (int i = 0; i < n; i++) {\n",
        "\t\ta[i] = rand() % n;\n",
        "\t\tcout << a[i] << \"\\t\";\n",
        "\t}\n",
        "\n",
        "\tcudaEvent_t start, end;\n",
        "\tint *ad, *bd;\n",
        "\tint size = n * sizeof(int);\n",
        "\tcudaMalloc(&ad, size);\n",
        "\tcudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "\tint grids = ceil(n * 1.0f / 256.0f);\n",
        "\tcudaMalloc(&bd, grids * sizeof(int));\n",
        "\n",
        "\tdim3 grid(grids, 1);\n",
        "\tdim3 block(1, 1);\n",
        "\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEventCreate(&end);\n",
        "\tcudaEventRecord(start);\n",
        "\n",
        "\twhile (n > 1) {\n",
        "\t\tmaxi<<<grids, block>>>(ad, bd, n);\n",
        "\t\tn = ceil(n * 1.0f / 256.0f);\n",
        "\t\tcudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "\t}\n",
        "\n",
        "\tcudaEventRecord(end);\n",
        "\tcudaEventSynchronize(end);\n",
        "\n",
        "\tfloat time = 0;\n",
        "\tcudaEventElapsedTime(&time, start, end);\n",
        "\n",
        "\tint ans[2];\n",
        "\tcudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tcout << \"The maximum element is : \" << ans[0] << endl;\n",
        "\n",
        "\tcout << \"The time required : \";\n",
        "\tcout << time << endl;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKRwuu_mldZq",
        "outputId": "9b982af9-326d-42b4-9619-53dd613ed5a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum element is : 0\n",
            "The time required : 0.003904\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kode Cuda Buat Tucil"
      ],
      "metadata": {
        "id": "DWwWFtU3pAon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cara Run :\n",
        "- upload \"cuda.cu\" yang telah kita buat\n",
        "- upload test_case.txt (kalo udah butuh test case) => ini buat tucil\n",
        "- jalankan command\n",
        "- testing sample => !time ./cuda\n",
        "- testing tucil => !time ./cuda < ./test_case/128.txt > output_cuda_128.txt"
      ],
      "metadata": {
        "id": "GI_qDy5qphaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc cuda.cu -o cuda"
      ],
      "metadata": {
        "id": "6ulISKKznSkx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Command Buat Jalanin test sample cuda\n",
        "!time ./cuda\n",
        "\n",
        "# Command Buat Tucil Cuda (ini masih dugaan sih)\n",
        "# !time ./cuda < ./test_case/128.txt > output_cuda_128.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64rmY0rKoMJg",
        "outputId": "10d1a131-2c4a-485d-9ba6-38fca4138709"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world from x.0 y.0 z.0!\n",
            "Hello world from x.1 y.0 z.0!\n",
            "Hello world from x.0 y.1 z.0!\n",
            "Hello world from x.1 y.1 z.0!\n",
            "Hello world from x.0 y.0 z.1!\n",
            "Hello world from x.1 y.0 z.1!\n",
            "Hello world from x.0 y.1 z.1!\n",
            "Hello world from x.1 y.1 z.1!\n",
            "Hello world from x.0 y.0 z.0!\n",
            "Hello world from x.1 y.0 z.0!\n",
            "Hello world from x.0 y.1 z.0!\n",
            "Hello world from x.1 y.1 z.0!\n",
            "Hello world from x.0 y.0 z.1!\n",
            "Hello world from x.1 y.0 z.1!\n",
            "Hello world from x.0 y.1 z.1!\n",
            "Hello world from x.1 y.1 z.1!\n",
            "Hello world from x.0 y.0 z.0!\n",
            "Hello world from x.1 y.0 z.0!\n",
            "Hello world from x.0 y.1 z.0!\n",
            "Hello world from x.1 y.1 z.0!\n",
            "Hello world from x.0 y.0 z.1!\n",
            "Hello world from x.1 y.0 z.1!\n",
            "Hello world from x.0 y.1 z.1!\n",
            "Hello world from x.1 y.1 z.1!\n",
            "Hello world from x.0 y.0 z.0!\n",
            "Hello world from x.1 y.0 z.0!\n",
            "Hello world from x.0 y.1 z.0!\n",
            "Hello world from x.1 y.1 z.0!\n",
            "Hello world from x.0 y.0 z.1!\n",
            "Hello world from x.1 y.0 z.1!\n",
            "Hello world from x.0 y.1 z.1!\n",
            "Hello world from x.1 y.1 z.1!\n",
            "\n",
            "real\t0m0.850s\n",
            "user\t0m0.015s\n",
            "sys\t0m0.748s\n"
          ]
        }
      ]
    }
  ]
}